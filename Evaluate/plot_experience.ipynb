{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to generate Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"PATH:/to/your/data\" # enter directory of log files\n",
    "filename_50 = foldername + \"50_sim\"\n",
    "filename_20 = foldername + \"20_sim\"\n",
    "filename_10 = foldername + \"10_sim\"\n",
    "filename_1 = foldername + \"1_sim\"\n",
    "filename_01 = foldername + \"01_sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 10 # simulations per setting\n",
    "epoch_num = 9 # which testing phase to plot (9 == 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indices for relevant data\n",
    "event_t = 1\n",
    "policy_t = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_t_look(data):\n",
    "    for t in range(270):\n",
    "        if data[t, policy_t] == 1 or (data[t, event_t] == 3 and data[t, policy_t] == 0):\n",
    "            return t\n",
    "    return 269"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_t_look_policy(data):\n",
    "    for t in range(270):\n",
    "        if data[t, policy_t] == 1:\n",
    "            return t\n",
    "    return 270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_t(data, t_look):\n",
    "    return  (270 - t_look)/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand-agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in hand-agent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_hand_50 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_hand_policy_50 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_50 + str(sim) + '_epoch' + str(epoch) + '_hand_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_hand_50[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_hand_policy_50[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed hand-agent data with 50% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_hand_20 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_hand_policy_20 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_20 + str(sim) + '_epoch' + str(epoch) + '_hand_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_hand_20[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_hand_policy_20[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed hand-agent data with 20% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_hand_10 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_hand_policy_10 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_10 + str(sim) + '_epoch' + str(epoch) + '_hand_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_hand_10[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_hand_policy_10[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed hand-agent data with 10% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_hand_1 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_hand_policy_1 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_1 + str(sim) + '_epoch' + str(epoch) + '_hand_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_hand_1[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_hand_policy_1[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed hand-agent data with 1% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_hand_01 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_hand_policy_01 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_01 + str(sim) + '_epoch' + str(epoch) + '_hand_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_hand_01[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_hand_policy_01[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed hand-agent data with 0.1% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_hand_mean_50 = np.mean(np.mean(looking_ts_hand_policy_50, axis=2), axis = 0)\n",
    "looking_ts_hand_sd_50 = np.std(np.mean(looking_ts_hand_policy_50, axis=2), axis=0)\n",
    "looking_ts_hand_mean_20 = np.mean(np.mean(looking_ts_hand_policy_20, axis=2), axis = 0)\n",
    "looking_ts_hand_sd_20 = np.std(np.mean(looking_ts_hand_policy_20, axis=2), axis=0)\n",
    "looking_ts_hand_mean_10 = np.mean(np.mean(looking_ts_hand_policy_10, axis=2), axis = 0)\n",
    "looking_ts_hand_sd_10 = np.std(np.mean(looking_ts_hand_policy_10, axis=2), axis=0)\n",
    "looking_ts_hand_mean_1 = np.mean(np.mean(looking_ts_hand_policy_1, axis=2), axis = 0)\n",
    "looking_ts_hand_sd_1 = np.std(np.mean(looking_ts_hand_policy_1, axis=2), axis=0)\n",
    "looking_ts_hand_mean_01 = np.mean(np.mean(looking_ts_hand_policy_01, axis=2), axis = 0)\n",
    "looking_ts_hand_sd_01 = np.std(np.mean(looking_ts_hand_policy_01, axis=2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claw-agent "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in claw-agent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_claw_50 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_claw_policy_50 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_50 + str(sim) + '_epoch' + str(epoch) + '_claw_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_claw_50[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_claw_policy_50[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed claw-agent data with 50% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_claw_20 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_claw_policy_20 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_20 + str(sim) + '_epoch' + str(epoch) + '_claw_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_claw_20[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_claw_policy_20[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed claw-agent data with 20% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_claw_10 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_claw_policy_10 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_10 + str(sim) + '_epoch' + str(epoch) + '_claw_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_claw_10[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_claw_policy_10[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed claw-agent data with 10% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_claw_1 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_claw_policy_1 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_1 + str(sim) + '_epoch' + str(epoch) + '_claw_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_claw_1[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_claw_policy_1[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed claw-agent data with 1% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_claw_01 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "looking_ts_claw_policy_01 = np.zeros((num_sims, 1, 10), dtype='float64')\n",
    "for sim in range(num_sims):\n",
    "    epoch = epoch_num\n",
    "    for run in range(10):\n",
    "        filename = filename_01 + str(sim) + '_epoch' + str(epoch) + '_claw_run' + str(run) + '.txt'\n",
    "        data = np.loadtxt(filename, dtype='float64', skiprows = 1, delimiter= ', ')\n",
    "        t_look = find_t_look(data)\n",
    "        t_look_policy = find_t_look_policy(data)\n",
    "        looking_ts_claw_01[sim, 0, run] = normalize_t(data, t_look)\n",
    "        looking_ts_claw_policy_01[sim, 0, run] = normalize_t(data, t_look_policy)\n",
    "    print(\"Processed claw-agent data with 0.1% reaching experience of simulation \" + str(sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "looking_ts_claw_mean_50 = np.mean(np.mean(looking_ts_claw_policy_50, axis=2), axis = 0)\n",
    "looking_ts_claw_sd_50 = np.std(np.mean(looking_ts_claw_policy_50, axis=2), axis=0)\n",
    "looking_ts_claw_mean_10 = np.mean(np.mean(looking_ts_claw_policy_10, axis=2), axis = 0)\n",
    "looking_ts_claw_sd_10 = np.std(np.mean(looking_ts_claw_policy_10, axis=2), axis=0)\n",
    "looking_ts_claw_mean_1 = np.mean(np.mean(looking_ts_claw_policy_1, axis=2), axis = 0)\n",
    "looking_ts_claw_sd_1 = np.std(np.mean(looking_ts_claw_policy_1, axis=2), axis=0)\n",
    "looking_ts_claw_mean_01 = np.mean(np.mean(looking_ts_claw_policy_01, axis=2), axis = 0)\n",
    "looking_ts_claw_sd_01 = np.std(np.mean(looking_ts_claw_policy_01, axis=2), axis=0)\n",
    "looking_ts_claw_mean_20 = np.mean(np.mean(looking_ts_claw_policy_20, axis=2), axis = 0)\n",
    "looking_ts_claw_sd_20 = np.std(np.mean(looking_ts_claw_policy_20, axis=2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice color definitions\n",
    "colors = [(0.368, 0.507, 0.71), (0.881, 0.611, 0.142),\n",
    "          (0.56, 0.692, 0.195), (0.923, 0.386, 0.209),\n",
    "          (0.528, 0.471, 0.701), (0.772, 0.432, 0.102),\n",
    "          (0.364, 0.619, 0.782), (0.572, 0.586, 0.) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# hand data\n",
    "x1 = range(5) - np.ones((5))* 0.15\n",
    "y1 = np.array([looking_ts_hand_mean_01, looking_ts_hand_mean_1, looking_ts_hand_mean_10, looking_ts_hand_mean_20, looking_ts_hand_mean_50]).reshape([5])\n",
    "err1 = np.array([looking_ts_hand_sd_01, looking_ts_hand_sd_1, looking_ts_hand_sd_10, looking_ts_hand_sd_20, looking_ts_hand_sd_50]).reshape([5])\n",
    "\n",
    "errorbars_hand = plt.errorbar(x= x1, y= y1, yerr= err1,  fmt='none', color=colors[0], markersize= 12, elinewidth = 3, marker='o')\n",
    "scatter_hand = plt.scatter(x1, y1, color=colors[0], s = 180)\n",
    "\n",
    "# claw data\n",
    "x2 = range(5) + np.ones((5))* 0.15\n",
    "y2 = [looking_ts_claw_mean_01, looking_ts_claw_mean_1, looking_ts_claw_mean_10, looking_ts_claw_mean_20, looking_ts_claw_mean_50]\n",
    "err2 = [looking_ts_claw_sd_01, looking_ts_claw_sd_1, looking_ts_claw_sd_10, looking_ts_claw_sd_20, looking_ts_claw_sd_50]\n",
    "\n",
    "errorbars_claw = plt.errorbar(x= x2, y= y2, yerr= err2, fmt='none', color=colors[3], markersize= 12, elinewidth = 3, marker='o')\n",
    "scatter_claw = plt.scatter(x2, y2, color=colors[3], s = 180)\n",
    "\n",
    "\n",
    "# Plot event boundaries\n",
    "plt.plot([-0.5, 5], [0.0, 0.0], 'k')\n",
    "plt.plot([-0.5, 5], [0.7, 0.7], 'k:')\n",
    "plt.plot([-0.5, 5], [1.7, 1.7], 'k:')\n",
    "plt.plot([-0.5, 5], [2.7, 2.7], 'k')\n",
    "plt.yticks([0.25, 1.25, 2.25], ('e_random', 'e_transport', 'e_reach'))\n",
    "\n",
    "# Dummy lines for legend\n",
    "dummyHand = plt.plot(-10, 0, color=colors[0], linewidth= 8)\n",
    "dummyClaw = plt.plot(-10, 0, color=colors[3], linewidth= 8)\n",
    "plt.legend((dummyHand[0], dummyClaw[0]), ('Hand', 'Claw'))\n",
    "\n",
    "plt.xlim([-0.5, 5])\n",
    "plt.xticks([0, 1, 2, 3, 4], ('0.1%', '1%', '10%', '20%', '50%'))\n",
    "plt.title('Time t of first activation of \\pi_{patient}')\n",
    "plt.xlabel('% E_grasp in training')\n",
    "\n",
    "#plt.show\n",
    "\n",
    "import tikzplotlib\n",
    "tikzplotlib.save(\"resultPlots/tikz_compare_experience.tex\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
